import { createClient } from "@supabase/supabase-js";
import { OpenAI } from "openai";
import ffmpeg from "fluent-ffmpeg";
import fs from "fs";
import os from "os";
import path from "path";
import Mux from "@mux/mux-node";

// --- INICIALIZACI√ìN DE CLIENTES ---
const supabaseClient = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);
const openAI = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const mux = new Mux(); // La librer√≠a usa las variables de entorno MUX_TOKEN_ID y MUX_TOKEN_SECRET autom√°ticamente

// --- FUNCI√ìN AUXILIAR PARA DESCARGAR CON REINTENTOS ---
const fetchWithRetry = async (url, retries = 5, delay = 3000) => {
  for (let i = 0; i < retries; i++) {
    console.log(
      `  - Intento de descarga ${i + 1}/${retries} desde ${url.substring(
        0,
        50
      )}...`
    );
    try {
      const response = await fetch(url);
      if (response.ok) {
        console.log("  - ‚úÖ Descarga exitosa (Status 200 OK).");
        return response;
      }
      // Si el error es 503 (Servicio No Disponible), esperamos y reintentamos.
      if (response.status === 503) {
        console.warn(
          `  - Aviso: Recibido Status 503 (Servicio No Disponible). Reintentando en ${
            delay / 1000
          }s...`
        );
        await new Promise((resolve) => setTimeout(resolve, delay));
        continue; // Pasa a la siguiente iteraci√≥n del bucle
      }
      // Para cualquier otro error (403, 404, etc.), fallamos inmediatamente.
      throw new Error(
        `Fallo de descarga no recuperable. Status: ${response.status}`
      );
    } catch (error) {
      // Captura errores de red (ej. DNS, conexi√≥n)
      console.warn(
        `  - Aviso: Error de red en el intento ${i + 1}.`,
        error.message
      );
      if (i === retries - 1) throw error; // Si es el √∫ltimo intento, lanzamos el error
      await new Promise((resolve) => setTimeout(resolve, delay));
    }
  }
  throw new Error(
    `Fallo al descargar el archivo despu√©s de ${retries} intentos.`
  );
};

// --- FUNCI√ìN AUXILIAR PARA ESPERAR EL MASTER DEL VIDEO ---
const waitForMasterAccess = async (
  muxAssetId,
  maxRetries = 12,
  delay = 10000
) => {
  // 12 reintentos de 10s = 2 min de espera max.
  for (let i = 0; i < maxRetries; i++) {
    console.log(
      `  - Intento ${
        i + 1
      }/${maxRetries}: Verificando estado del master para el asset ${muxAssetId}...`
    );

    const asset = await mux.video.assets.retrieve(muxAssetId);

    if (asset?.master?.status === "ready" && asset.master.url) {
      console.log("  - ‚úÖ Master est√° listo y la URL est√° disponible.");
      return asset.master.url;
    }
    if (asset?.master?.status === "errored") {
      throw new Error("Mux report√≥ un error al preparar el archivo master.");
    }

    await new Promise((resolve) => setTimeout(resolve, delay));
  }
  throw new Error("El archivo master no estuvo disponible a tiempo (timeout).");
};

// --- FUNCI√ìN AUXILIAR PARA OBTENER DURACI√ìN ---
const getVideoDuration = (videoPath) => {
  return new Promise((resolve, reject) => {
    ffmpeg.ffprobe(videoPath, (err, metadata) => {
      if (err) {
        console.error("üî• Error al sondear el video con ffprobe:", err.message);
        return reject(err);
      }
      const duration = metadata.format.duration;
      console.log(`‚è±Ô∏è Duraci√≥n del video obtenida: ${duration} segundos.`);
      resolve(duration);
    });
  });
};

// --- FUNCI√ìN AUXILIAR PARA DIVIDIR AUDIO ---
const splitVideoIntoAudioChunks = (videoPath, tempDir) => {
  return new Promise((resolve, reject) => {
    const chunkPathPrefix = path.join(tempDir, "chunk_");
    const chunkFilePattern = `${chunkPathPrefix}%03d.mp3`;

    ffmpeg(videoPath)
      .outputOptions([
        "-f",
        "segment",
        "-segment_time",
        "600",
        "-vn",
        "-acodec",
        "libmp3lame",
        "-q:a",
        "2",
      ])
      .output(chunkFilePattern)
      .on("end", () => {
        const chunks = fs
          .readdirSync(tempDir)
          .filter((file) => file.startsWith("chunk_") && file.endsWith(".mp3"));
        console.log(`‚úÖ Video dividido en ${chunks.length} trozos de audio.`);
        resolve(chunks.map((chunk) => path.join(tempDir, chunk)));
      })
      .on("error", (err) => {
        console.error("üî• Error en ffmpeg:", err.message);
        reject(err);
      })
      .run();
  });
};

// --- HANDLER PRINCIPAL DE LA API ---
export default async function handler(req, res) {
  if (req.method !== "POST")
    return res.status(405).json({ error: "Method Not Allowed" });

  const authToken = req.headers.authorization?.split(" ")[1];
  if (authToken !== process.env.PROCESSING_API_SECRET)
    return res.status(401).json({ error: "Unauthorized" });

  const { claseId, muxAssetId } = req.body;
  if (!claseId || !muxAssetId)
    return res
      .status(400)
      .json({ error: "Faltan par√°metros claseId o muxAssetId." });

  const tempDir = fs.mkdtempSync(path.join(os.tmpdir(), "video-processing-"));
  const localVideoPath = path.join(tempDir, "source_video.mp4");

  try {
    console.log(
      `[Clase ID: ${claseId}] Iniciando procesamiento para Mux Asset ID: ${muxAssetId}`
    );

    if (!mux)
      throw new Error("El cliente de Mux no se inicializ√≥ correctamente.");

    // 1. ESPERAR Y OBTENER LA URL DE DESCARGA
    const downloadUrl = await waitForMasterAccess(muxAssetId);

    // 2. DESCARGAR EL VIDEO CON L√ìGICA DE REINTENTOS
    const videoResponse = await fetchWithRetry(downloadUrl);

    fs.writeFileSync(
      localVideoPath,
      Buffer.from(await videoResponse.arrayBuffer())
    );
    console.log(`‚úÖ Video descargado y guardado localmente.`);

    // 3. PROCESAMIENTO CON FFMPEG Y OPENAI
    const durationInSeconds = await getVideoDuration(localVideoPath);
    await supabaseClient
      .from("clases")
      .update({ duracion_segundos: durationInSeconds })
      .eq("id", claseId);
    console.log(`‚úÖ Duraci√≥n guardada: ${durationInSeconds}s`);

    const audioChunksPaths = await splitVideoIntoAudioChunks(
      localVideoPath,
      tempDir
    );
    console.log(`‚úÖ Audio dividido en ${audioChunksPaths.length} trozos.`);

    let fullTranscription = "";
    for (const chunkPath of audioChunksPaths) {
      const transcription = await openAI.audio.transcriptions.create({
        file: fs.createReadStream(chunkPath),
        model: "whisper-1",
        language: "es",
        prompt:
          "Esta es una clase de ingl√©s para hispanohablantes. El audio contiene una mezcla de espa√±ol e ingl√©s, con terminolog√≠a gramatical como pronombres, verbos, adjetivos y tiempos verbales.",
      });
      fullTranscription += transcription.text + " ";
    }
    console.log(`‚úÖ Transcripci√≥n completa generada.`);

    const textChunks = fullTranscription
      .split(". ")
      .filter(Boolean)
      .map((s) => s.trim() + ".");
    console.log(
      `‚úÖ Texto dividido en ${textChunks.length} fragmentos para embeddings.`
    );
    for (const chunk of textChunks) {
      const embeddingResponse = await openAI.embeddings.create({
        model: "text-embedding-3-small",
        input: chunk,
      });
      const [embedding] = embeddingResponse.data;
      await supabaseClient.from("clase_embeddings").insert({
        clase_id: claseId,
        contenido: chunk,
        embedding: embedding.embedding,
      });
    }
    console.log(`‚úÖ Embeddings guardados.`);

    // 4. √âXITO
    console.log(`üéâ [Clase ID: ${claseId}] Proceso completado.`);
    res
      .status(200)
      .json({
        success: true,
        message: `Procesados ${textChunks.length} fragmentos.`,
      });
  } catch (error) {
    console.error(
      `\n--- ‚ùå ERROR FATAL en la API para la clase ID ${claseId} ---\n`,
      error
    );
    res.status(500).json({ error: error.message });
  } finally {
    // 5. LIMPIEZA
    if (fs.existsSync(tempDir)) {
      fs.rmSync(tempDir, { recursive: true, force: true });
      console.log(`üßπ Directorio temporal eliminado para clase ${claseId}.`);
    }
  }
}

export const config = {
  api: {
    bodyParser: {
      sizeLimit: "50mb",
    },
  },
};
